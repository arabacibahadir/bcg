{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T12:17:53.227098Z",
     "start_time": "2024-08-26T12:17:48.277060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.python.keras.engine import data_adapter\n",
    "\n",
    "def _is_distributed_dataset(ds):\n",
    "    return isinstance(ds, data_adapter.input_lib.DistributedDatasetSpec)\n",
    "\n",
    "data_adapter._is_distributed_dataset = _is_distributed_dataset"
   ],
   "id": "d288cc90a8d006e8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T12:20:02.300366700Z",
     "start_time": "2024-08-26T12:17:55.236441Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "def build_autoencoder(input_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(64, activation='relu')(input_layer)\n",
    "    encoded = Dense(32, activation='relu')(encoded)\n",
    "    decoded = Dense(64, activation='relu')(encoded)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "    \n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "    \n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder, encoder\n",
    "\n",
    "def load_and_preprocess_data(folder_path):\n",
    "    all_data = []\n",
    "    file_list = os.listdir(folder_path)\n",
    "    for file_name in file_list:\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "            all_data.append(df.values)\n",
    "    all_data = np.concatenate(all_data, axis=0)\n",
    "    return all_data\n",
    "\n",
    "# Feature extraction\n",
    "def feature_extraction(folder_path):\n",
    "    data = load_and_preprocess_data(folder_path)\n",
    "    input_dim = data.shape[1]\n",
    "    autoencoder, encoder = build_autoencoder(input_dim)\n",
    "    autoencoder.fit(data, data, epochs=1, batch_size=512, shuffle=True)\n",
    "    features = encoder.predict(data)\n",
    "    return features\n",
    "\n",
    "folder_path = r'C:\\Users\\bahad\\PycharmProjects\\kpmakale\\dataset_final2'  \n",
    "features = feature_extraction(folder_path)\n",
    "print(\"Extracted features shape:\", features.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m75979/75979\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m95s\u001B[0m 1ms/step - loss: 7.8451e-05\n",
      "\u001B[1m  37272/1215652\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m13:10\u001B[0m 671us/step"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 43\u001B[0m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m features\n\u001B[0;32m     42\u001B[0m folder_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mbahad\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mPycharmProjects\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mkpmakale\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mdataset_final2\u001B[39m\u001B[38;5;124m'\u001B[39m  \n\u001B[1;32m---> 43\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[43mfeature_extraction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfolder_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtracted features shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, features\u001B[38;5;241m.\u001B[39mshape)\n",
      "Cell \u001B[1;32mIn[2], line 39\u001B[0m, in \u001B[0;36mfeature_extraction\u001B[1;34m(folder_path)\u001B[0m\n\u001B[0;32m     37\u001B[0m autoencoder, encoder \u001B[38;5;241m=\u001B[39m build_autoencoder(input_dim)\n\u001B[0;32m     38\u001B[0m autoencoder\u001B[38;5;241m.\u001B[39mfit(data, data, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 39\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[43mencoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m features\n",
      "File \u001B[1;32m~\\PycharmProjects\\kpmakale\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\PycharmProjects\\kpmakale\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:514\u001B[0m, in \u001B[0;36mTensorFlowTrainer.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks)\u001B[0m\n\u001B[0;32m    512\u001B[0m batch_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict_function(data)\n\u001B[0;32m    513\u001B[0m outputs \u001B[38;5;241m=\u001B[39m append_to_outputs(batch_outputs, outputs)\n\u001B[1;32m--> 514\u001B[0m \u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_predict_batch_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutputs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_outputs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_predicting:\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\kpmakale\\.venv\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py:126\u001B[0m, in \u001B[0;36mCallbackList.on_predict_batch_end\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m    124\u001B[0m logs \u001B[38;5;241m=\u001B[39m logs \u001B[38;5;129;01mor\u001B[39;00m {}\n\u001B[0;32m    125\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[1;32m--> 126\u001B[0m     \u001B[43mcallback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_predict_batch_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\kpmakale\\.venv\\Lib\\site-packages\\keras\\src\\callbacks\\progbar_logger.py:66\u001B[0m, in \u001B[0;36mProgbarLogger.on_predict_batch_end\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_predict_batch_end\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch, logs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;66;03m# Don't pass prediction results.\u001B[39;00m\n\u001B[1;32m---> 66\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_progbar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\kpmakale\\.venv\\Lib\\site-packages\\keras\\src\\callbacks\\progbar_logger.py:95\u001B[0m, in \u001B[0;36mProgbarLogger._update_progbar\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseen \u001B[38;5;241m=\u001B[39m batch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m  \u001B[38;5;66;03m# One-indexed.\u001B[39;00m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 95\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprogbar\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinalize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\kpmakale\\.venv\\Lib\\site-packages\\keras\\src\\utils\\progbar.py:182\u001B[0m, in \u001B[0;36mProgbar.update\u001B[1;34m(self, current, values, finalize)\u001B[0m\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m finalize:\n\u001B[0;32m    180\u001B[0m     message \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 182\u001B[0m \u001B[43mio_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprint_msg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mline_break\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prev_total_width \u001B[38;5;241m=\u001B[39m total_width\n\u001B[0;32m    184\u001B[0m message \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\kpmakale\\.venv\\Lib\\site-packages\\keras\\src\\utils\\io_utils.py:99\u001B[0m, in \u001B[0;36mprint_msg\u001B[1;34m(message, line_break)\u001B[0m\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     98\u001B[0m         sys\u001B[38;5;241m.\u001B[39mstdout\u001B[38;5;241m.\u001B[39mwrite(message)\n\u001B[1;32m---> 99\u001B[0m     \u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstdout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflush\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    101\u001B[0m     logging\u001B[38;5;241m.\u001B[39minfo(message)\n",
      "File \u001B[1;32m~\\PycharmProjects\\kpmakale\\.venv\\Lib\\site-packages\\ipykernel\\iostream.py:609\u001B[0m, in \u001B[0;36mOutStream.flush\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    607\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpub_thread\u001B[38;5;241m.\u001B[39mschedule(evt\u001B[38;5;241m.\u001B[39mset)\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;66;03m# and give a timeout to avoid\u001B[39;00m\n\u001B[1;32m--> 609\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mevt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflush_timeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    610\u001B[0m         \u001B[38;5;66;03m# write directly to __stderr__ instead of warning because\u001B[39;00m\n\u001B[0;32m    611\u001B[0m         \u001B[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001B[39;00m\n\u001B[0;32m    612\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIOStream.flush timed out\u001B[39m\u001B[38;5;124m\"\u001B[39m, file\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39m__stderr__)\n\u001B[0;32m    613\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:629\u001B[0m, in \u001B[0;36mEvent.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    627\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[1;32m--> 629\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:331\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    330\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 331\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    332\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    333\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_and_preprocess_data_with_labels(folder_path):\n",
    "    all_data = []\n",
    "    labels = []\n",
    "    file_list = os.listdir(folder_path)\n",
    "    \n",
    "    for file_name in file_list:\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "            all_data.append(df.values)\n",
    "            \n",
    "            # Create label based on filename\n",
    "            if \"_H_\" in file_name:\n",
    "                labels.append(1)  # Hypertension\n",
    "            elif \"_N_\" in file_name:\n",
    "                labels.append(0)  # Healthy\n",
    "                \n",
    "    all_data = np.concatenate(all_data, axis=0)\n",
    "    labels = np.array(labels).repeat(df.shape[0])  # Repeat label for each row in the file\n",
    "    \n",
    "    return all_data, labels\n"
   ],
   "id": "af945d57fc28eba1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Feature extraction with labels\n",
    "def feature_extraction_with_labels(folder_path):\n",
    "    data, labels = load_and_preprocess_data_with_labels(folder_path)\n",
    "    input_dim = data.shape[1]\n",
    "    autoencoder, encoder = build_autoencoder(input_dim)\n",
    "    autoencoder.fit(data, data, epochs=5, batch_size=512, shuffle=True)\n",
    "    features = encoder.predict(data)\n",
    "    return features, labels\n"
   ],
   "id": "61cc3f3e0d67c181"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import LSTM\n",
    "folder_path = r'C:\\Users\\bahad\\PycharmProjects\\kpmakale\\dataset_final2'\n",
    "features, labels = feature_extraction_with_labels(folder_path)\n",
    "print(\"Extracted features shape:\", features.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "# Reshape features for LSTM input\n",
    "num_samples = features.shape[0]\n",
    "num_features = features.shape[1]\n",
    "lstm_input = features.reshape((num_samples, 1, num_features))\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(lstm_input, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(1, num_features), activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n"
   ],
   "id": "f52c2c5c724a4c5d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
